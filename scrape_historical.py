#!/usr/bin/env python3
"""
Scrape additional historical seasons and merge with existing data.
This script avoids re-scraping 2022-2024 which we already have.

Features:
- Progress tracking with resume capability
- Quota monitoring
- Prioritizes recent seasons first
"""
import os
import sys
import json
from datetime import datetime
from typing import List, Dict, Set
import pandas as pd
from tqdm import tqdm

from dotenv import load_dotenv
load_dotenv()

from api_client import api_client
from scraper import WorldCup2026Scraper
from config import (
    OUTPUT_DIR,
    PLAYERS_OUTPUT_DIR,
    STATISTICS_OUTPUT_DIR,
)

# Historical seasons to scrape (Pro plan has access to these)
# Prioritize recent seasons first (more relevant for prediction)
# We already have 2022, 2023, 2024 - so skip those
HISTORICAL_SEASONS = [2021, 2020, 2019, 2018, 2017, 2016, 2015]

# Progress file
HISTORICAL_PROGRESS_FILE = f"{OUTPUT_DIR}/historical_scrape_progress.json"

# Minimum quota to keep as buffer
MIN_QUOTA_BUFFER = 200


class ProgressTracker:
    """Track scraping progress for resume capability."""
    
    def __init__(self, progress_file: str = HISTORICAL_PROGRESS_FILE):
        self.progress_file = progress_file
        self.progress = self.load()
    
    def load(self) -> dict:
        """Load progress from file."""
        if os.path.exists(self.progress_file):
            try:
                with open(self.progress_file, 'r') as f:
                    return json.load(f)
            except Exception:
                pass
        return {
            "completed_teams": [],  # Teams fully scraped
            "scraped_seasons": {},  # {team_name: {player_id: [seasons]}}
            "api_calls_made": 0,
            "started_at": datetime.now().isoformat(),
            "last_updated": datetime.now().isoformat()
        }
    
    def save(self):
        """Save progress to file."""
        self.progress["last_updated"] = datetime.now().isoformat()
        with open(self.progress_file, 'w') as f:
            json.dump(self.progress, f, indent=2)
    
    def is_team_completed(self, team_name: str) -> bool:
        return team_name in self.progress["completed_teams"]
    
    def get_player_scraped_seasons(self, team_name: str, player_id: int) -> List[int]:
        """Get seasons already scraped for a player in this historical run."""
        key = str(player_id)
        return self.progress["scraped_seasons"].get(team_name, {}).get(key, [])
    
    def mark_player_season(self, team_name: str, player_id: int, season: int):
        """Mark a season as scraped for a player."""
        if team_name not in self.progress["scraped_seasons"]:
            self.progress["scraped_seasons"][team_name] = {}
        key = str(player_id)
        if key not in self.progress["scraped_seasons"][team_name]:
            self.progress["scraped_seasons"][team_name][key] = []
        if season not in self.progress["scraped_seasons"][team_name][key]:
            self.progress["scraped_seasons"][team_name][key].append(season)
    
    def mark_team_completed(self, team_name: str):
        if team_name not in self.progress["completed_teams"]:
            self.progress["completed_teams"].append(team_name)
        self.save()
    
    def add_api_calls(self, count: int):
        self.progress["api_calls_made"] += count
    
    def get_stats(self) -> str:
        return (
            f"Teams completed: {len(self.progress['completed_teams'])}/32 | "
            f"API calls: {self.progress['api_calls_made']}"
        )


def check_quota() -> int:
    """Check remaining API quota. Returns remaining requests."""
    try:
        status = api_client.get_account_status()
        response = status.get("response", {})
        requests_info = response.get("requests", {})
        current = requests_info.get("current", 0)
        limit = requests_info.get("limit_day", 7500)
        return limit - current
    except Exception as e:
        print(f"  ‚ö†Ô∏è Could not check quota: {e}")
        return 0


def get_existing_seasons(team_name: str) -> List[int]:
    """Get seasons already scraped for a team."""
    safe_name = team_name.replace(" ", "_").lower()
    stats_file = f"{STATISTICS_OUTPUT_DIR}/{safe_name}_player_statistics.csv"
    
    if os.path.exists(stats_file):
        df = pd.read_csv(stats_file)
        return sorted(df['season'].unique().tolist())
    return []


def merge_and_save_stats(team_name: str, new_stats_df: pd.DataFrame, team_id: int):
    """Merge new historical stats with existing data and save."""
    safe_name = team_name.replace(" ", "_").lower()
    stats_file = f"{STATISTICS_OUTPUT_DIR}/{safe_name}_player_statistics.csv"
    
    if os.path.exists(stats_file):
        existing_df = pd.read_csv(stats_file)
        print(f"  Existing data: {len(existing_df)} records, seasons {sorted(existing_df['season'].unique())}")
    else:
        existing_df = pd.DataFrame()
        print(f"  No existing data found")
    
    if new_stats_df.empty:
        print(f"  No new historical data found")
        return existing_df
    
    # Add national team info to new stats
    new_stats_df["national_team_id"] = team_id
    new_stats_df["national_team_name"] = team_name
    
    print(f"  New historical data: {len(new_stats_df)} records, seasons {sorted(new_stats_df['season'].unique())}")
    
    # Combine and deduplicate
    if not existing_df.empty:
        combined_df = pd.concat([existing_df, new_stats_df], ignore_index=True)
        # Remove duplicates based on key columns
        combined_df = combined_df.drop_duplicates(
            subset=['player_id', 'season', 'team_id', 'league_id'],
            keep='first'
        )
    else:
        combined_df = new_stats_df
    
    # Sort by player and season
    combined_df = combined_df.sort_values(['player_name', 'season', 'team_name'])
    
    # Save
    combined_df.to_csv(stats_file, index=False)
    print(f"  ‚úÖ Saved {len(combined_df)} total records to {stats_file}")
    print(f"     Seasons now: {sorted(combined_df['season'].unique())}")
    
    return combined_df


def scrape_historical_for_team(
    scraper: WorldCup2026Scraper,
    team_id: int,
    team_name: str,
    seasons_to_scrape: List[int],
    progress: ProgressTracker,
) -> tuple[pd.DataFrame, int, bool]:
    """
    Scrape historical seasons for a single team.
    Returns: (DataFrame with stats, api_calls_made, quota_exhausted)
    """
    
    # Check if team already completed
    if progress.is_team_completed(team_name):
        print(f"  ‚è≠Ô∏è Team already completed in previous run")
        return pd.DataFrame(), 0, False
    
    # Get existing data info (from CSV files, not progress tracker)
    existing_seasons = get_existing_seasons(team_name)
    
    # Load squad
    safe_name = team_name.replace(" ", "_").lower()
    squad_file = f"{PLAYERS_OUTPUT_DIR}/{safe_name}_squad.csv"
    
    if not os.path.exists(squad_file):
        print(f"  ‚ùå No squad file found for {team_name}")
        return pd.DataFrame(), 0, False
    
    # Check file size (empty placeholder files are 1 byte)
    if os.path.getsize(squad_file) < 10:
        print(f"  ‚ùå Squad file is empty for {team_name}")
        return pd.DataFrame(), 0, False
    
    try:
        squad_df = pd.read_csv(squad_file)
        if squad_df.empty or 'player_id' not in squad_df.columns:
            print(f"  ‚ùå Squad file has no player data for {team_name}")
            return pd.DataFrame(), 0, False
    except Exception as e:
        print(f"  ‚ùå Error reading squad file: {e}")
        return pd.DataFrame(), 0, False
    
    # Filter out seasons we already have in CSV
    new_seasons = [s for s in seasons_to_scrape if s not in existing_seasons]
    
    if not new_seasons:
        print(f"  ‚è≠Ô∏è All requested seasons already in CSV: {existing_seasons}")
        progress.mark_team_completed(team_name)
        return pd.DataFrame(), 0, False
    
    print(f"  üìä Scraping seasons {new_seasons} for {len(squad_df)} players")
    print(f"     Already have in CSV: {existing_seasons}")
    
    all_player_stats = []
    api_calls_made = 0
    quota_exhausted = False
    
    for idx, player in squad_df.iterrows():
        if pd.isna(player.get("player_id")):
            continue
            
        player_id = int(player["player_id"])
        player_name = player.get("player_name", f"Player {player_id}")
        
        # Check which seasons still need to be scraped for this player
        already_scraped = progress.get_player_scraped_seasons(team_name, player_id)
        seasons_for_player = [s for s in new_seasons if s not in already_scraped]
        
        if not seasons_for_player:
            continue  # All seasons for this player already done
        
        # Check quota before making requests
        if api_calls_made > 0 and api_calls_made % 50 == 0:
            remaining = check_quota()
            print(f"     [Quota check: {remaining} remaining]")
            if remaining < MIN_QUOTA_BUFFER:
                print(f"  ‚ö†Ô∏è Quota too low ({remaining} < {MIN_QUOTA_BUFFER}). Stopping.")
                quota_exhausted = True
                break
        
        # Scrape this player's historical stats
        player_stats = []
        
        for season in seasons_for_player:
            try:
                stats_response = scraper.api.get_player_statistics(player_id, season)
                api_calls_made += 1
                
                if stats_response:
                    player_data = stats_response[0]
                    player_info = player_data.get("player", {})
                    birth = player_info.get("birth", {})
                    
                    for stat in player_data.get("statistics", []):
                        league = stat.get("league", {})
                        team = stat.get("team", {})
                        games = stat.get("games", {})
                        substitutes = stat.get("substitutes", {})
                        shots = stat.get("shots", {})
                        goals_data = stat.get("goals", {})
                        passes = stat.get("passes", {})
                        tackles = stat.get("tackles", {})
                        duels = stat.get("duels", {})
                        dribbles = stat.get("dribbles", {})
                        fouls = stat.get("fouls", {})
                        cards = stat.get("cards", {})
                        penalty = stat.get("penalty", {})
                        
                        player_stats.append({
                            # Player info
                            "player_id": player_info.get("id"),
                            "player_name": player_info.get("name"),
                            "firstname": player_info.get("firstname"),
                            "lastname": player_info.get("lastname"),
                            "nationality": player_info.get("nationality"),
                            "birth_date": birth.get("date"),
                            "birth_place": birth.get("place"),
                            "birth_country": birth.get("country"),
                            "age": player_info.get("age"),
                            "height": player_info.get("height"),
                            "weight": player_info.get("weight"),
                            "injured": player_info.get("injured"),
                            "photo": player_info.get("photo"),
                            # Team & League
                            "season": season,
                            "team_id": team.get("id"),
                            "team_name": team.get("name"),
                            "league_id": league.get("id"),
                            "league_name": league.get("name"),
                            "league_country": league.get("country"),
                            # Games
                            "position": games.get("position"),
                            "appearances": games.get("appearences"),
                            "lineups": games.get("lineups"),
                            "minutes": games.get("minutes"),
                            "rating": games.get("rating"),
                            "captain": games.get("captain"),
                            # Substitutes
                            "substitutes_in": substitutes.get("in"),
                            "substitutes_out": substitutes.get("out"),
                            "substitutes_bench": substitutes.get("bench"),
                            # Shooting
                            "shots_total": shots.get("total"),
                            "shots_on_target": shots.get("on"),
                            # Goals
                            "goals": goals_data.get("total"),
                            "goals_conceded": goals_data.get("conceded"),
                            "assists": goals_data.get("assists"),
                            "saves": goals_data.get("saves"),
                            # Passing
                            "passes_total": passes.get("total"),
                            "passes_key": passes.get("key"),
                            "passes_accuracy": passes.get("accuracy"),
                            # Defensive
                            "tackles_total": tackles.get("total"),
                            "tackles_blocks": tackles.get("blocks"),
                            "tackles_interceptions": tackles.get("interceptions"),
                            # Duels
                            "duels_total": duels.get("total"),
                            "duels_won": duels.get("won"),
                            # Dribbles
                            "dribbles_attempts": dribbles.get("attempts"),
                            "dribbles_success": dribbles.get("success"),
                            "dribbles_past": dribbles.get("past"),
                            # Fouls
                            "fouls_drawn": fouls.get("drawn"),
                            "fouls_committed": fouls.get("committed"),
                            # Cards
                            "cards_yellow": cards.get("yellow"),
                            "cards_yellowred": cards.get("yellowred"),
                            "cards_red": cards.get("red"),
                            # Penalties
                            "penalty_won": penalty.get("won"),
                            "penalty_committed": penalty.get("commited"),
                            "penalty_scored": penalty.get("scored"),
                            "penalty_missed": penalty.get("missed"),
                            "penalty_saved": penalty.get("saved"),
                        })
                
                # Mark season as done for this player
                progress.mark_player_season(team_name, player_id, season)
                
            except Exception as e:
                print(f"  ‚ö†Ô∏è Error fetching stats for {player_name} season {season}: {e}")
        
        if player_stats:
            all_player_stats.extend(player_stats)
        
        # Save progress periodically
        if api_calls_made % 20 == 0:
            progress.add_api_calls(20)
            progress.save()
    
    # Don't mark team as completed here - do it after merge succeeds in main()
    
    progress.add_api_calls(api_calls_made % 20)  # Add remaining calls
    progress.save()
    
    if all_player_stats:
        return pd.DataFrame(all_player_stats), api_calls_made, quota_exhausted
    return pd.DataFrame(), api_calls_made, quota_exhausted


def main():
    """Main entry point."""
    print("=" * 70)
    print("üï∞Ô∏è  HISTORICAL DATA SCRAPER")
    print(f"   Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   Historical seasons to scrape: {HISTORICAL_SEASONS}")
    print("=" * 70)
    
    # Initialize progress tracker
    progress = ProgressTracker()
    print(f"\nüìã Progress: {progress.get_stats()}")
    
    # Check API quota
    print("\nüìä Checking API quota...")
    remaining = check_quota()
    print(f"   Remaining requests: {remaining}")
    
    if remaining < MIN_QUOTA_BUFFER:
        print(f"   ‚ö†Ô∏è Quota too low ({remaining} < {MIN_QUOTA_BUFFER}). Wait for reset.")
        return
    
    if remaining < 500:
        print("   ‚ö†Ô∏è Low quota. Will scrape what we can.")
    
    # Initialize scraper
    scraper = WorldCup2026Scraper()
    
    # Get list of teams from existing data
    teams_file = f"{OUTPUT_DIR}/teams/world_cup_2026_teams.csv"
    if not os.path.exists(teams_file):
        print(f"‚ùå Teams file not found: {teams_file}")
        return
    
    teams_df = pd.read_csv(teams_file)
    print(f"\nüìã Found {len(teams_df)} teams")
    
    # Track overall progress
    total_api_calls = 0
    quota_exhausted = False
    
    for idx, team in teams_df.iterrows():
        team_id = team["team_id"]
        team_name = team["team_name"]
        
        if pd.isna(team_id):
            continue
        
        team_id = int(team_id)
        
        print(f"\n{'='*60}")
        print(f"üìå [{idx+1}/{len(teams_df)}] {team_name} (ID: {team_id})")
        print(f"{'='*60}")
        
        try:
            # Scrape historical data with progress tracking
            new_stats_df, api_calls, quota_exhausted = scrape_historical_for_team(
                scraper, team_id, team_name, HISTORICAL_SEASONS, progress
            )
            
            total_api_calls += api_calls
            
            # Merge with existing data
            if not new_stats_df.empty:
                merge_and_save_stats(team_name, new_stats_df, team_id)
                # Only mark as completed after successful merge
                progress.mark_team_completed(team_name)
                print(f"  ‚úÖ Team marked as completed")
            elif progress.is_team_completed(team_name):
                # Already completed before, just skipped
                pass
            else:
                # No new data scraped (maybe all seasons already in CSV)
                progress.mark_team_completed(team_name)
            
            if quota_exhausted:
                print(f"\n‚è∏Ô∏è Stopping due to low quota. Run again tomorrow to continue.")
                print(f"   Progress saved. {progress.get_stats()}")
                break
                
        except KeyboardInterrupt:
            print("\n\n‚è∏Ô∏è Interrupted by user. Progress saved.")
            progress.save()
            break
        except Exception as e:
            print(f"  ‚ùå Error: {e}")
            import traceback
            traceback.print_exc()
    
    # Update the combined all-teams statistics file
    print("\nüìä Updating combined statistics file...")
    all_stats = []
    for filename in os.listdir(STATISTICS_OUTPUT_DIR):
        if filename.endswith("_player_statistics.csv") and filename != "all_player_statistics.csv":
            filepath = f"{STATISTICS_OUTPUT_DIR}/{filename}"
            try:
                df = pd.read_csv(filepath)
                if not df.empty:
                    all_stats.append(df)
            except Exception:
                pass
    
    if all_stats:
        combined_all = pd.concat(all_stats, ignore_index=True)
        # Deduplicate
        combined_all = combined_all.drop_duplicates(
            subset=['player_id', 'season', 'team_id', 'league_id'],
            keep='first'
        )
        combined_all = combined_all.sort_values(['player_name', 'season', 'team_name'])
        all_stats_file = f"{STATISTICS_OUTPUT_DIR}/all_player_statistics.csv"
        combined_all.to_csv(all_stats_file, index=False)
        print(f"‚úÖ Combined statistics: {len(combined_all)} records")
        print(f"   Seasons: {sorted(combined_all['season'].unique())}")
    
    print("\n" + "=" * 70)
    print("üèÅ HISTORICAL SCRAPING SESSION COMPLETE")
    print(f"   Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   API calls this session: {total_api_calls}")
    print(f"   {progress.get_stats()}")
    if quota_exhausted:
        print("   ‚ö†Ô∏è Run again tomorrow to continue with remaining teams/seasons")
    print("=" * 70)


if __name__ == "__main__":
    main()
